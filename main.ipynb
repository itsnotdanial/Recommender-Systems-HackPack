{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2df592",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Looking to incorporate some AI into your hack? Look no further. In this guide, I’ll walk you through a simple, hands-on introduction to recommender systems, where we build a playlist recommender.\n",
    "\n",
    "This guide is primarily aimed at beginners, but I’ve also linked some more advanced resources at the bottom if you want to go deeper.\n",
    "\n",
    "---\n",
    "\n",
    "# Prerequisites\n",
    "\n",
    "We’ll be using a combination of **pandas** (for data preprocessing) and **scikit-learn** (`sklearn`) for the actual learning and predictions.\n",
    "\n",
    "No deep understanding of the underlying math is required—this guide is focused on a practical, hands-on approach. However, if you’re not familiar with pandas, I’d recommend taking a quick look at [this W3Schools pandas tutorial](https://www.w3schools.com/python/pandas/default.asp).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60ed860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dania\\grind\\uni\\durhack\\recommender-systems-hackpack\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting numpy>=1.20.3 (from pandas)\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dania\\grind\\uni\\durhack\\recommender-systems-hackpack\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.6/10.8 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/10.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.0/10.8 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.1/10.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.2/10.8 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/10.8 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.8/14.9 MB 10.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.7/14.9 MB 9.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.5/14.9 MB 9.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.6/14.9 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.4/14.9 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.5/14.9 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.6/14.9 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02b8021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\dania\\grind\\uni\\durhack\\recommender-systems-hackpack\\.venv\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl.metadata (58 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.3.2-cp38-cp38-win_amd64.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.6/9.3 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.4/9.3 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.7/9.3 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.0/9.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.1/9.3 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.3 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 6.6 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "   ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/42.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/42.2 MB 8.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 3.1/42.2 MB 7.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 6.9 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.8/42.2 MB 6.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 7.1/42.2 MB 6.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 7.9/42.2 MB 6.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 9.2/42.2 MB 6.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 10.2/42.2 MB 6.1 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 11.5/42.2 MB 6.0 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 12.3/42.2 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 13.4/42.2 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 14.7/42.2 MB 5.7 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 16.0/42.2 MB 5.8 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 5.9 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 20.2/42.2 MB 5.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 21.5/42.2 MB 5.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 22.5/42.2 MB 5.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 5.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 26.2/42.2 MB 5.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 27.5/42.2 MB 5.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 28.8/42.2 MB 5.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 33.0/42.2 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 34.3/42.2 MB 6.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 35.1/42.2 MB 5.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.9/42.2 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 38.5/42.2 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 39.3/42.2 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 40.9/42.2 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 42.2/42.2 MB 5.8 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.3.2 scipy-1.10.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009341ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b0a174",
   "metadata": {},
   "source": [
    "Here, I just loaded in some datasets that I got from [Kaggle](https://www.kaggle.com/). It's a great source for open data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900cc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the datasets\n",
    "\n",
    "artist_df = pd.read_csv(\"SpotGenTrack/Data Sources/spotify_artists.csv\")\n",
    "tracks_df = pd.read_csv(\"SpotGenTrack/Data Sources/spotify_tracks.csv\")\n",
    "low_level_audio_df = pd.read_csv(\"SpotGenTrack/Features Extracted/low_level_audio_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf4be09",
   "metadata": {},
   "source": [
    "We're going to use low-level audio features to make the actual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accec535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Chroma_1', 'Chroma_10', 'Chroma_11', 'Chroma_12', 'Chroma_2', 'Chroma_3', 'Chroma_4', 'Chroma_5', 'Chroma_6', 'Chroma_7', 'Chroma_8', 'Chroma_9', 'MEL_1', 'MEL_10', 'MEL_100', 'MEL_101', 'MEL_102', 'MEL_103', 'MEL_104', 'MEL_105', 'MEL_106', 'MEL_107', 'MEL_108', 'MEL_109', 'MEL_11', 'MEL_110', 'MEL_111', 'MEL_112', 'MEL_113', 'MEL_114', 'MEL_115', 'MEL_116', 'MEL_117', 'MEL_118', 'MEL_119', 'MEL_12', 'MEL_120', 'MEL_121', 'MEL_122', 'MEL_123', 'MEL_124', 'MEL_125', 'MEL_126', 'MEL_127', 'MEL_128', 'MEL_13', 'MEL_14', 'MEL_15', 'MEL_16', 'MEL_17', 'MEL_18', 'MEL_19', 'MEL_2', 'MEL_20', 'MEL_21', 'MEL_22', 'MEL_23', 'MEL_24', 'MEL_25', 'MEL_26', 'MEL_27', 'MEL_28', 'MEL_29', 'MEL_3', 'MEL_30', 'MEL_31', 'MEL_32', 'MEL_33', 'MEL_34', 'MEL_35', 'MEL_36', 'MEL_37', 'MEL_38', 'MEL_39', 'MEL_4', 'MEL_40', 'MEL_41', 'MEL_42', 'MEL_43', 'MEL_44', 'MEL_45', 'MEL_46', 'MEL_47', 'MEL_48', 'MEL_49', 'MEL_5', 'MEL_50', 'MEL_51', 'MEL_52', 'MEL_53', 'MEL_54', 'MEL_55', 'MEL_56', 'MEL_57', 'MEL_58', 'MEL_59', 'MEL_6', 'MEL_60', 'MEL_61', 'MEL_62', 'MEL_63', 'MEL_64', 'MEL_65', 'MEL_66', 'MEL_67', 'MEL_68', 'MEL_69', 'MEL_7', 'MEL_70', 'MEL_71', 'MEL_72', 'MEL_73', 'MEL_74', 'MEL_75', 'MEL_76', 'MEL_77', 'MEL_78', 'MEL_79', 'MEL_8', 'MEL_80', 'MEL_81', 'MEL_82', 'MEL_83', 'MEL_84', 'MEL_85', 'MEL_86', 'MEL_87', 'MEL_88', 'MEL_89', 'MEL_9', 'MEL_90', 'MEL_91', 'MEL_92', 'MEL_93', 'MEL_94', 'MEL_95', 'MEL_96', 'MEL_97', 'MEL_98', 'MEL_99', 'MFCC_1', 'MFCC_10', 'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_2', 'MFCC_20', 'MFCC_21', 'MFCC_22', 'MFCC_23', 'MFCC_24', 'MFCC_25', 'MFCC_26', 'MFCC_27', 'MFCC_28', 'MFCC_29', 'MFCC_3', 'MFCC_30', 'MFCC_31', 'MFCC_32', 'MFCC_33', 'MFCC_34', 'MFCC_35', 'MFCC_36', 'MFCC_37', 'MFCC_38', 'MFCC_39', 'MFCC_4', 'MFCC_40', 'MFCC_41', 'MFCC_42', 'MFCC_43', 'MFCC_44', 'MFCC_45', 'MFCC_46', 'MFCC_47', 'MFCC_48', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'Spectral_contrast_1', 'Spectral_contrast_2', 'Spectral_contrast_3', 'Spectral_contrast_4', 'Spectral_contrast_5', 'Spectral_contrast_6', 'Spectral_contrast_7', 'Tonnetz_1', 'Tonnetz_2', 'Tonnetz_3', 'Tonnetz_4', 'Tonnetz_5', 'Tonnetz_6', 'ZCR', 'entropy_energy', 'spectral_bandwith', 'spectral_centroid', 'spectral_rollOff_max', 'spectral_rollOff_min', 'track_id']\n"
     ]
    }
   ],
   "source": [
    "print(list(low_level_audio_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3bb052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = \"Arctic Monkeys\"\n",
    "song = \"Mardy Bum\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efdd718",
   "metadata": {},
   "source": [
    "The dataset is split across multiple CSV files, so we'll do some light preprocessing to locate the song the user is interested in. Once we’ve identified it, we can generate a playlist of similar tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49faf2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the correct track\n",
    "\n",
    "artist_data = artist_df.loc[artist_df[\"name\"] == artist]\n",
    "artist_id = artist_data[\"id\"].iloc[0]  \n",
    "\n",
    "# Find songs with matching name\n",
    "name_matches = tracks_df[tracks_df[\"name\"] == song]\n",
    "\n",
    "\n",
    "# Get the correct song with the matching artist \n",
    "matches = []\n",
    "for idx, row in name_matches.iterrows():\n",
    "    if artist_id in row[\"artists_id\"]:\n",
    "        matches.append(idx)\n",
    "\n",
    "song_data = tracks_df.loc[matches]\n",
    "\n",
    "track_id = song_data[\"id\"].iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc0fd3b",
   "metadata": {},
   "source": [
    "Here, we extract the audio features for our target song, as well as the full feature dataframe we'll compare it against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25d94b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_level_audio = low_level_audio_df.loc[low_level_audio_df[\"track_id\"] == track_id]\n",
    "target = low_level_audio.drop(columns=[\"track_id\"])\n",
    "features = low_level_audio_df.drop(columns=[\"track_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2b128",
   "metadata": {},
   "source": [
    "This is where the actual magic happens. The `cosine_similarity` function calculates the angle between feature vectors—rows in our dataset. Songs with smaller angles (i.e., higher cosine similarity) to the target are considered more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1538c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(target, features)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529e1f4",
   "metadata": {},
   "source": [
    "Now we’ll add the similarity scores back into the dataframe and sort the songs by their similarity to the target track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df6a52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_level_audio_df['similarity'] = similarities\n",
    "\n",
    "# Get top recommendations\n",
    "#TOD0 remove the exact match\n",
    "recommended = low_level_audio_df.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "best_10_track_ids = []\n",
    "\n",
    "for index, row in recommended.head(10).iterrows() :\n",
    "    best_10_track_ids.append(row[\"track_id\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0d132",
   "metadata": {},
   "source": [
    "All that's left is to retrieve the song names using their track numbers and enjoy the playlist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3624443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mardy Bum\n",
      "Rage\n",
      "Sticky\n",
      "Siempre Soñe\n",
      "Wanna Be Like You\n",
      "Tu Salto\n",
      "New Beginning\n",
      "Is\n",
      "Be Your Shadow\n",
      "Bad Blood\n"
     ]
    }
   ],
   "source": [
    "playlist = []\n",
    "for id in best_10_track_ids:\n",
    "    track_row = tracks_df[tracks_df[\"id\"] == id]\n",
    "    song_name = track_row[\"name\"].iloc[0]\n",
    "    playlist.append(song_name)\n",
    "    print(song_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c7ed3a",
   "metadata": {},
   "source": [
    "Well done! You've just built your first recommender system. If you want to take it a step further, I recommend checking out the following resources:\n",
    "\n",
    "- [The difference between content and collaborative filtering](https://thecleverprogrammer.com/2023/04/20/content-based-filtering-and-collaborative-filtering-difference/)\n",
    "- [An in-depth guide to best practices for recommender systems](https://github.com/recommenders-team/recommenders)\n",
    "- [Theory behind recommender systems](https://nafeea3000.medium.com/recommender-systems-c8db209dd0d3)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
